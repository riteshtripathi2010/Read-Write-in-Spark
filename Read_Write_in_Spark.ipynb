{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Writing and Validating Data in PySpark\n",
    "\n",
    "I will be: \n",
    "\n",
    " - Reading in Data\n",
    " - Partioned Files\n",
    " - Validating Data\n",
    " - Specifying Data Types\n",
    " - Writing Data\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ReadWriteVal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb993931610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's create our PySpark instance!\n",
    "\n",
    "# PC users can use the next two lines of code but mac users don't need it\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"ReadWriteVal\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "A DataFrame is equivalent to a relational table in Spark SQL, and can be created using various functions in SparkSession.\n",
    "\n",
    "First let's try reading in a csv file containing a list of students and their grades.\n",
    "\n",
    "**Source:** https://www.kaggle.com/spscientist/students-performance-in-exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|    standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|    standard|                   none|        90|           95|           93|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|        47|           57|           44|\n",
      "|  male|       group C|               some college|    standard|                   none|        76|           78|           75|\n",
      "|female|       group B|         associate's degree|    standard|                   none|        71|           83|           78|\n",
      "|female|       group B|               some college|    standard|              completed|        88|           95|           92|\n",
      "|  male|       group B|               some college|free/reduced|                   none|        40|           43|           39|\n",
      "|  male|       group D|                high school|free/reduced|              completed|        64|           64|           67|\n",
      "|female|       group B|                high school|free/reduced|                   none|        38|           60|           50|\n",
      "|  male|       group C|         associate's degree|    standard|                   none|        58|           54|           52|\n",
      "|  male|       group D|         associate's degree|    standard|                   none|        40|           52|           43|\n",
      "|female|       group B|                high school|    standard|                   none|        65|           81|           73|\n",
      "|  male|       group A|               some college|    standard|              completed|        78|           72|           70|\n",
      "|female|       group A|            master's degree|    standard|                   none|        50|           53|           58|\n",
      "|female|       group C|           some high school|    standard|                   none|        69|           75|           78|\n",
      "|  male|       group C|                high school|    standard|                   none|        88|           89|           86|\n",
      "|female|       group B|           some high school|free/reduced|                   none|        18|           32|           28|\n",
      "|  male|       group C|            master's degree|free/reduced|              completed|        46|           42|           46|\n",
      "|female|       group C|         associate's degree|free/reduced|                   none|        54|           58|           61|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by reading a basic csv dataset\n",
    "# Let Spark know about the header and infer the Schema types!\n",
    "\n",
    "students =spark.read.csv(\"/Users/riteshtripathi/Desktop/Pyspark DataScience/Read Write Validate Datasets/students.csv\", \n",
    "                         inferSchema = True, header = True)\n",
    "\n",
    "# Some csv data\n",
    "#students = spark.read.csv(path+'students.csv',inferSchema=True,header=True)\n",
    "\n",
    "students.show()\n",
    "#this will look more ugly to read as it will have alot of colns to show\n",
    "#to show better, convert dataframe to pandas\n",
    "students.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parquet Files**\n",
    "\n",
    "Now try reading in a parquet file. This is most common data type in the big data world.\n",
    "Why? because it is the most compact file storage method (even better than zipped files!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03 10:55:29|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03 20:04:03|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|   Accountant IV|        |\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_dttm</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-03 10:55:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-03 20:04:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Albert</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>afreeman1@is.gd</td>\n",
       "      <td>Male</td>\n",
       "      <td>218.111.175.34</td>\n",
       "      <td></td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/16/1968</td>\n",
       "      <td>150280.17</td>\n",
       "      <td>Accountant IV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-03 04:09:31</td>\n",
       "      <td>3</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>emorgan2@altervista.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.161.136.94</td>\n",
       "      <td>6767119071901597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2/1/1960</td>\n",
       "      <td>144972.51</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-03 03:36:21</td>\n",
       "      <td>4</td>\n",
       "      <td>Denise</td>\n",
       "      <td>Riley</td>\n",
       "      <td>driley3@gmpg.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>140.35.109.83</td>\n",
       "      <td>3576031598965625</td>\n",
       "      <td>China</td>\n",
       "      <td>4/8/1997</td>\n",
       "      <td>90263.05</td>\n",
       "      <td>Senior Cost Accountant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_dttm  id first_name last_name                    email  \\\n",
       "0 2016-02-03 10:55:29   1     Amanda    Jordan         ajordan0@com.com   \n",
       "1 2016-02-03 20:04:03   2     Albert   Freeman          afreeman1@is.gd   \n",
       "2 2016-02-03 04:09:31   3     Evelyn    Morgan  emorgan2@altervista.org   \n",
       "3 2016-02-03 03:36:21   4     Denise     Riley         driley3@gmpg.org   \n",
       "\n",
       "   gender      ip_address                cc    country  birthdate     salary  \\\n",
       "0  Female     1.197.201.2  6759521864920116  Indonesia   3/8/1971   49756.53   \n",
       "1    Male  218.111.175.34                       Canada  1/16/1968  150280.17   \n",
       "2  Female    7.161.136.94  6767119071901597     Russia   2/1/1960  144972.51   \n",
       "3  Female   140.35.109.83  3576031598965625      China   4/8/1997   90263.05   \n",
       "\n",
       "                    title comments  \n",
       "0        Internal Auditor    1E+02  \n",
       "1           Accountant IV           \n",
       "2     Structural Engineer           \n",
       "3  Senior Cost Accountant           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to read parquet files\n",
    "#these files are better than zip and csv files\n",
    "#big organization use these kind of files\n",
    "parquet = spark.read.parquet(\"/Users/riteshtripathi/Desktop/Pyspark DataScience/Read Write Validate Datasets/users1.parquet\")\n",
    "parquet.show(2)\n",
    "parquet.limit(4).toPandas()\n",
    "\n",
    "# Parquet files are partioned files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partitioned Parquet Files**\n",
    "\n",
    "Actually most big datasets will be partitioned. Here is how you can collect all the pieces (parts) of the dataset in one simple command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03 10:55:29|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03 20:04:03|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|   Accountant IV|        |\n",
      "+-------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_dttm</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>cc</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-03 10:55:29</td>\n",
       "      <td>1</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>ajordan0@com.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.197.201.2</td>\n",
       "      <td>6759521864920116</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3/8/1971</td>\n",
       "      <td>49756.53</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>1E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-03 20:04:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Albert</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>afreeman1@is.gd</td>\n",
       "      <td>Male</td>\n",
       "      <td>218.111.175.34</td>\n",
       "      <td></td>\n",
       "      <td>Canada</td>\n",
       "      <td>1/16/1968</td>\n",
       "      <td>150280.17</td>\n",
       "      <td>Accountant IV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-03 04:09:31</td>\n",
       "      <td>3</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>emorgan2@altervista.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.161.136.94</td>\n",
       "      <td>6767119071901597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2/1/1960</td>\n",
       "      <td>144972.51</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-03 03:36:21</td>\n",
       "      <td>4</td>\n",
       "      <td>Denise</td>\n",
       "      <td>Riley</td>\n",
       "      <td>driley3@gmpg.org</td>\n",
       "      <td>Female</td>\n",
       "      <td>140.35.109.83</td>\n",
       "      <td>3576031598965625</td>\n",
       "      <td>China</td>\n",
       "      <td>4/8/1997</td>\n",
       "      <td>90263.05</td>\n",
       "      <td>Senior Cost Accountant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_dttm  id first_name last_name                    email  \\\n",
       "0 2016-02-03 10:55:29   1     Amanda    Jordan         ajordan0@com.com   \n",
       "1 2016-02-03 20:04:03   2     Albert   Freeman          afreeman1@is.gd   \n",
       "2 2016-02-03 04:09:31   3     Evelyn    Morgan  emorgan2@altervista.org   \n",
       "3 2016-02-03 03:36:21   4     Denise     Riley         driley3@gmpg.org   \n",
       "\n",
       "   gender      ip_address                cc    country  birthdate     salary  \\\n",
       "0  Female     1.197.201.2  6759521864920116  Indonesia   3/8/1971   49756.53   \n",
       "1    Male  218.111.175.34                       Canada  1/16/1968  150280.17   \n",
       "2  Female    7.161.136.94  6767119071901597     Russia   2/1/1960  144972.51   \n",
       "3  Female   140.35.109.83  3576031598965625      China   4/8/1997   90263.05   \n",
       "\n",
       "                    title comments  \n",
       "0        Internal Auditor    1E+02  \n",
       "1           Accountant IV           \n",
       "2     Structural Engineer           \n",
       "3  Senior Cost Accountant           "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since i have many parquet files, to read all of them at once:\n",
    "partitioned = spark.read.parquet(\"/Users/riteshtripathi/Desktop/Pyspark DataScience/Read Write Validate Datasets/\"+'users*')\n",
    "#anything that starts with users.. load those files\n",
    "partitioned.show(2)\n",
    "partitioned.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also opt to read in only a specific set of paritioned parquet files. Say for example that you only wanted users1 and users2 and not users3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------------+\n",
      "|  name|favorite_color|favorite_numbers|\n",
      "+------+--------------+----------------+\n",
      "|Alyssa|          null|  [3, 9, 15, 20]|\n",
      "|   Ben|           red|              []|\n",
      "|Alyssa|          null|  [3, 9, 15, 20]|\n",
      "|   Ben|           red|              []|\n",
      "+------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that the .option(\"basePath\", path) option is used to override the automatic function\n",
    "# that will exclude the partitioned variable in resulting dataframe. \n",
    "# I prefer to have the partitioning info in my new dataframe personally. \n",
    "# Now, just to get User 1 and User 2 i need\n",
    "#users1_2 = spark.read.option(\"basePath\", path).parquet(path+'users1.parquet', path+'users2.parquet')\n",
    "users1_2 = spark.read.parquet(\"/Users/riteshtripathi/Desktop/Pyspark DataScience/Read Write Validate Datasets/\"+'users1.parquet', +'users2.parquet')\n",
    "users1_2.show()\n",
    "#got issues with this command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Data\n",
    "\n",
    "Next you will want to validate that you dataframe was read in correct. We will get into more detailed data evaluation later on but first we need to ensure that all the variable types were infered correctly and that the values actually made it in... sometimes they don't :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|   lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|standard|                   none|        90|           95|           93|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n",
      "+-------+----------+-------------+\n",
      "|summary|math score|reading score|\n",
      "+-------+----------+-------------+\n",
      "|  count|      1000|         1000|\n",
      "|    min|         0|           17|\n",
      "|    max|       100|          100|\n",
      "+-------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an inital view of your dataframe\n",
    "students.show(3)\n",
    "\n",
    "students.printSchema()\n",
    "\n",
    "students.columns\n",
    "\n",
    "students.describe()\n",
    "\n",
    "students.schema['math score'].dataType\n",
    "\n",
    "students.select(\"math score\", \"reading score\").summary(\"count\", \"min\", \"max\").show()\n",
    "#will get summary for each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If your dataframe is more than just a few variables, this method is way better\n",
    "students.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the types here:\n",
    "print(type(students))\n",
    "studentsPdf = students.toPandas()\n",
    "print(type(studentsPdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n",
      "None\n",
      "\n",
      "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
      "\n",
      "DataFrame[summary: string, gender: string, race/ethnicity: string, parental level of education: string, lunch: string, test preparation course: string, math score: string, reading score: string, writing score: string]\n"
     ]
    }
   ],
   "source": [
    "# A Solid Summary of your data:\n",
    "\n",
    "#show the data (like df.head())\n",
    "print(students.printSchema())\n",
    "print(\"\")\n",
    "print(students.columns)\n",
    "print(\"\")\n",
    "print(students.describe()) # Not so fond of this one but to each their own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntegerType"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need to get the type of just ONE column by name you can use this function:\n",
    "students.schema['math score'].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        math score|\n",
      "+-------+------------------+\n",
      "|  count|              1000|\n",
      "|   mean|            66.089|\n",
      "| stddev|15.163080096009454|\n",
      "|    min|                 0|\n",
      "|    max|               100|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neat \"describe\" function\n",
    "students.describe(['math score']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------------+\n",
      "|summary|math score|reading score|writing score|\n",
      "+-------+----------+-------------+-------------+\n",
      "|  count|      1000|         1000|         1000|\n",
      "|    min|         0|           17|           10|\n",
      "|    25%|        57|           59|           57|\n",
      "|    75%|        77|           79|           79|\n",
      "|    max|       100|          100|          100|\n",
      "+-------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary function\n",
    "students.select(\"math score\", \"reading score\",\"writing score\").summary(\"count\", \"min\", \"25%\", \"75%\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to specify data types as you read in datasets.\n",
    "\n",
    "Some data types make it easier to infer schema (like tabular formats such as csv which we will show later). \n",
    "\n",
    "However you often have to set the schema yourself if you aren't dealing with a .read method that doesn't have inferSchema() built-in.\n",
    "\n",
    "Spark has all the tools you need for this, it just requires a very specific structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,DateType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create the list of Structure fields\n",
    "    * :param name: string, name of the field.\n",
    "    * :param dataType: :class:`DataType` of the field.\n",
    "    * :param nullable: boolean, whether the field can be null (None) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField(\"name\", StringType(), True),\n",
    "               StructField(\"email\", StringType(), True),\n",
    "               StructField(\"city\", StringType(), True),\n",
    "               StructField(\"mac\", StringType(), True),\n",
    "               StructField(\"timestamp\", DateType(), True),\n",
    "               StructField(\"creditcard\", StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)\n",
    "#creating an object to hold the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a .json file this time :) \n",
    "\n",
    "**Source:** https://gist.github.com/raine/da15845f332a2fb8937b344504abfbe0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = spark.read.json(\"/Users/riteshtripathi/Desktop/Pyspark DataScience/Read Write Validate Datasets/\"+'people.json', \n",
    "                         schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- mac: string (nullable = true)\n",
      " |-- timestamp: date (nullable = true)\n",
      " |-- creditcard: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>mac</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>creditcard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keeley Bosco</td>\n",
       "      <td>katlyn@jenkinsmaggio.net</td>\n",
       "      <td>Lake Gladysberg</td>\n",
       "      <td>08:fd:0b:cd:77:f7</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rubye Jerde</td>\n",
       "      <td>juvenal@johnston.name</td>\n",
       "      <td>None</td>\n",
       "      <td>90:4d:fa:42:63:a2</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1228-1221-1221-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss Darian Breitenberg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>f9:0e:d3:40:cb:e9</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                     email             city  \\\n",
       "0                     None                      None             None   \n",
       "1             Keeley Bosco  katlyn@jenkinsmaggio.net  Lake Gladysberg   \n",
       "2              Rubye Jerde     juvenal@johnston.name             None   \n",
       "3  Miss Darian Breitenberg                      None             None   \n",
       "\n",
       "                 mac   timestamp           creditcard  \n",
       "0               None        None                 None  \n",
       "1  08:fd:0b:cd:77:f7  2015-04-25  1228-1221-1221-1431  \n",
       "2  90:4d:fa:42:63:a2  2015-04-25  1228-1221-1221-1431  \n",
       "3  f9:0e:d3:40:cb:e9  2015-04-25                 None  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.printSchema()\n",
    "people.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data\n",
    "\n",
    "First let's just try writing a simple csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the funky naming convention of the file in your output folder. There is no way to directly change this. \n",
    "students.write.mode(\"overwrite\").csv('write_test.csv')\n",
    "#this wil save the file with a different file name, which is in partioned type\n",
    "#to better save it in a better naming, follow the below code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the strange naming convention of the output file in the path that you specified. Spark uses Hadoop File Format, which requires data to be partitioned - that's why you have part- files. If you want to rename your written files to a more user friendly format, you can do that using the method below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.java_gateway import java_import\n",
    "java_import(spark._jvm, 'org.apache.hadoop.fs.Path')\n",
    "\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "file = fs.globStatus(spark._jvm.Path('write_test.csv/part*'))[0].getPath().getName()\n",
    "fs.rename(spark._jvm.Path('write_test.csv/' + file), spark._jvm.Path('write_test2.csv')) #these two need to be different\n",
    "fs.delete(spark._jvm.Path('write_test.csv'), True)\n",
    "\n",
    "#the file will be saved as write_test2.csv \n",
    "#and then i can double click on the name and mention whatever name i need to give"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writting Parquet files\n",
    "\n",
    "Now let's try writing a parquet file. This is best practice for big data as it is the most compact storage method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users1_2.write.mode(\"overwrite\").parquet('parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who got an error attempting to run the above code. Try this solution: https://stackoverflow.com/questions/59220832/unable-to-write-spark-dataframe-to-a-parquet-file-format-to-c-drive-in-pyspark\n",
    "\n",
    "#### Writting Partitioned Parquet Files\n",
    "\n",
    "Now try to write a partioned parquet file... super fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition by gender\n",
    "# you can partition also by several variables too\n",
    "users1_2.write.mode(\"overwrite\").partitionBy(\"gender\").parquet('part_parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writting your own dataframes here!\n",
    "\n",
    "You can also create your own dataframes directly here in your Juypter Notebook too if you want. \n",
    "\n",
    "Like this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [('Pear',10),('Orange',36),('Banana',123),('Kiwi',48),('Peach',16),('Strawberry',1)]\n",
    "df = spark.createDataFrame(values,['fruit','quantity'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
